{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0db13a-193a-4a81-936f-81bc50b4c539",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#7A74D9;\">Pytorch (Backend) Geometric Baseline</h1>\n",
    "\n",
    "## 1] Notes: \n",
    "\n",
    "1.  Neighborhood aggregation modules\n",
    "    a. \n",
    "2.  Graph Convolutional Modules\n",
    "\n",
    "    a. GraphConv a GCN layer\n",
    "    \n",
    "    b. RelGraphConv a relational graph convolution layer\n",
    "    \n",
    "    c. TAGConv Topology Adaptive Graph Conolutional layer \n",
    "    \n",
    "    d. GATConv Graph attention network \n",
    "    \n",
    "    e. EdgeConv\n",
    "    \n",
    "    f. SAGEConv \n",
    "    \n",
    "    g. and there many more in [dgl.ai Conv Layers](https://docs.dgl.ai/en/latest/api/python/nn.pytorch.html#module-dgl.nn.pytorch.conv)\n",
    "    \n",
    "## On the limimitions\n",
    "\n",
    "https://tkipf.github.io/graph-convolutional-networks/\n",
    "\n",
    "https://www.inference.vc/how-powerful-are-graph-convolutions-review-of-kipf-welling-2016-2/\n",
    "\n",
    "\n",
    "GCNS are optimal in the spectral domain. For this type of domain, using the Fourier transform is argued to have some limitations when the data scales up requiring relaxations. Thus, learning over graphs using GCNs is limited due to first order approcimation of a given graph reduced to a 2D lattice (which works great for image problems) but may not so easily generalize to graphs or non image-like structure. For more, see [Huszar/2016](https://www.inference.vc/how-powerful-are-graph-convolutions-review-of-kipf-welling-2016-2/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3483a-67bf-4b9d-9df9-3da515b7dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge scikit-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84dc19b2-36f4-416a-8c99-bd60b9c1668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pytorch-geometric -c rusty1s -c conda-forge -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b0dbf8-1308-4fde-a087-be300a922f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72da6938-8729-4e42-87ba-1ad2a5d03474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cpu.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ba66ab-3e9e-4b3a-8031-3420dd0a50bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cpu.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f76a631-8794-45f8-a09d-369c23e00094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(out.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee5872-e20b-4293-a35f-30e3dbc2ef23",
   "metadata": {},
   "source": [
    "<hr></hr>\n",
    "\n",
    "<h1 style=\"color:#7A74D9;\">Import Libraries</h1>\n",
    "\n",
    "A baseline GNN with DGL and pytorch backend example end-to-end referenced from this blog by [Builders][1].\n",
    "\n",
    "[1]: https://buildersbox.corp-sansan.com/entry/2020/10/12/110000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0111118c-c071-435a-a30a-cf94c555c467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "# from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "# dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import CoraGraphDataset\n",
    "import dgl.function as fn\n",
    "\n",
    "import time\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb9786a7-6b90-4189-8cba-472413d78ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset = CoraGraphDataset()\n",
    "graph = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "173c2e48-83e8-4ae9-a57c-d990253cc0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'train_mask': tensor([ True,  True,  True,  ..., False, False, False])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.ndata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9891bfe-2392-4769-8a52-abea1ece5b86",
   "metadata": {},
   "source": [
    "Verifies that there are more intra-class edges than inter-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced5c9d5-ba78-4132-8ec8-4e16870a19d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intra-class edges percent: 0.6994\n"
     ]
    }
   ],
   "source": [
    "# find all the nodes labelled with class 0\n",
    "label0_nodes = th.nonzero(graph.ndata['label'] == 0).squeeze()\n",
    "\n",
    "# find all the edges pointing to class 0 nodes\n",
    "src, _ = graph.in_edges(label0_nodes)\n",
    "src_labels = graph.ndata['label'][src]\n",
    "\n",
    "# find all the edges whose both endpoints are in class 0\n",
    "intra_src = th.nonzero(src_labels == 0)\n",
    "print('Intra-class edges percent: %.4f' % (len(intra_src) / len(src_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f9feb8c-c34e-4de2-aba3-f34cd21e4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "gcn_reduce = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac81fd1-6a1d-4368-9ea8-a598e33eff1b",
   "metadata": {},
   "source": [
    "## GNNLayer Module \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83f9c95e-e55b-41f6-90a0-cc94051bacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = feature\n",
    "            g.update_all(gcn_msg, gcn_reduce)\n",
    "            h = g.ndata['h']\n",
    "            return self.linear(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27ce534a-d9cb-42be-9e4f-56e520f43de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = GCNLayer(1433, 16)\n",
    "        self.layer2 = GCNLayer(16, 7)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = F.relu(self.layer1(g, features))\n",
    "        x = self.layer2(g, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a6f0058-2386-4767-9ddf-236c5d5843b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        logits = model(g, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = th.max(logits, dim=1)\n",
    "        correct = th.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e7800da-f51e-4b7f-95a3-f7fe72d70079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): GCNLayer(\n",
      "    (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
      "  )\n",
      "  (layer2): GCNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f456ec1d-0f77-4df2-b83b-e667184a2a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 1.9875 | Test Acc 0.0660 | Time(s) 0.0555\n",
      "Epoch 00010 | Loss 1.8442 | Test Acc 0.1400 | Time(s) 0.0285\n",
      "Epoch 00020 | Loss 1.6958 | Test Acc 0.3440 | Time(s) 0.0286\n",
      "Epoch 00030 | Loss 1.5462 | Test Acc 0.4250 | Time(s) 0.0292\n",
      "Epoch 00040 | Loss 1.4093 | Test Acc 0.4900 | Time(s) 0.0326\n",
      "Epoch 00050 | Loss 1.2916 | Test Acc 0.5760 | Time(s) 0.0313\n",
      "Epoch 00060 | Loss 1.1861 | Test Acc 0.6200 | Time(s) 0.0304\n",
      "Epoch 00070 | Loss 1.0877 | Test Acc 0.6480 | Time(s) 0.0286\n",
      "Epoch 00080 | Loss 0.9962 | Test Acc 0.6720 | Time(s) 0.0333\n",
      "Epoch 00090 | Loss 0.9119 | Test Acc 0.6790 | Time(s) 0.0419\n",
      "Epoch 00100 | Loss 0.8350 | Test Acc 0.6880 | Time(s) 0.0357\n",
      "Epoch 00110 | Loss 0.7656 | Test Acc 0.6950 | Time(s) 0.0393\n",
      "Epoch 00120 | Loss 0.7034 | Test Acc 0.6960 | Time(s) 0.0305\n",
      "Epoch 00130 | Loss 0.6482 | Test Acc 0.7020 | Time(s) 0.0392\n",
      "Epoch 00140 | Loss 0.5991 | Test Acc 0.7050 | Time(s) 0.0299\n",
      "Epoch 00150 | Loss 0.5551 | Test Acc 0.7080 | Time(s) 0.0311\n",
      "Epoch 00160 | Loss 0.5155 | Test Acc 0.7070 | Time(s) 0.0285\n",
      "Epoch 00170 | Loss 0.4797 | Test Acc 0.7090 | Time(s) 0.0284\n",
      "Epoch 00180 | Loss 0.4471 | Test Acc 0.7070 | Time(s) 0.0288\n",
      "Epoch 00190 | Loss 0.4174 | Test Acc 0.7120 | Time(s) 0.0302\n",
      "Epoch 00200 | Loss 0.3903 | Test Acc 0.7130 | Time(s) 0.0286\n",
      "Epoch 00210 | Loss 0.3654 | Test Acc 0.7100 | Time(s) 0.0355\n",
      "Epoch 00220 | Loss 0.3426 | Test Acc 0.7100 | Time(s) 0.0341\n",
      "Epoch 00230 | Loss 0.3217 | Test Acc 0.7110 | Time(s) 0.0293\n",
      "Epoch 00240 | Loss 0.3024 | Test Acc 0.7090 | Time(s) 0.0353\n"
     ]
    }
   ],
   "source": [
    "optimizer = th.optim.Adam(net.parameters(), lr=1e-3)\n",
    "dur = []\n",
    "for epoch in range(250):\n",
    "    t0 = time.time()\n",
    "\n",
    "    net.train()\n",
    "    logits = net(graph, graph.ndata['feat'])\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    loss = F.nll_loss(logp[graph.ndata['train_mask']], graph.ndata['label'][graph.ndata['train_mask']])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    acc = evaluate(net, graph, graph.ndata['feat'], graph.ndata['label'], graph.ndata['test_mask'])\n",
    "    if epoch%10==0:\n",
    "        print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
    "            epoch, loss.item(), acc, time.time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a699a11-4c45-4eed-85d6-496d3847d94b",
   "metadata": {},
   "source": [
    "<hr></hr>\n",
    "\n",
    "<h1 style=\"color:#7A74D9;\">1] Node Classification with GNN</h1>\n",
    "\n",
    "A baseline GNN with DGL and pytorch backend example end-to-end referenced from this blog by [dgl.ai][1].\n",
    "\n",
    "[1]: https://docs.dgl.ai/en/latest/new-tutorial/1_introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79af232e-6552-43bf-a7b1-84bd415e2b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Number of categories: 7\n"
     ]
    }
   ],
   "source": [
    "# === Loading Cora Dataset\n",
    "\n",
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "print('Number of categories:', dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "792074fb-ae6a-4248-bffe-8d9fa011e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c55f6b6-de72-4f8a-b010-983f1b547ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features\n",
      "{'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'train_mask': tensor([ True,  True,  True,  ..., False, False, False])}\n",
      "Edge Features\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print ('Node features')\n",
    "print(g.ndata)\n",
    "print('Edge Features')\n",
    "print(g.edata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a428c824-ad2f-4063-a50b-64f41a160af2",
   "metadata": {},
   "source": [
    "There are no edge features, but there are \n",
    "- feat below showing a total of 2708\n",
    "- label\n",
    "- test_mask\n",
    "- train_mask\n",
    "- val_mask a boolean tensor prededfined as whether or not the node is in the validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84e45b92-4530-41cb-af8a-23ec6536b861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.ndata['feat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183e967-4115-40f2-a42e-3f2c84fae999",
   "metadata": {},
   "source": [
    "## Defining a Graph Convolutional Network (GCN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c64fc59-aa14-44c8-9af1-60eee51451fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "# Create the model with given dimensions\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c180baa5-bd98-4a73-9e04-18b2283f8485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.946, val acc: 0.130 (best 0.130), test acc: 0.110 (best 0.110)\n",
      "In epoch 5, loss: 1.886, val acc: 0.462 (best 0.462), test acc: 0.487 (best 0.487)\n",
      "In epoch 10, loss: 1.799, val acc: 0.552 (best 0.552), test acc: 0.570 (best 0.570)\n",
      "In epoch 15, loss: 1.687, val acc: 0.638 (best 0.638), test acc: 0.643 (best 0.643)\n",
      "In epoch 20, loss: 1.553, val acc: 0.678 (best 0.678), test acc: 0.691 (best 0.691)\n",
      "In epoch 25, loss: 1.399, val acc: 0.698 (best 0.698), test acc: 0.713 (best 0.713)\n",
      "In epoch 30, loss: 1.231, val acc: 0.708 (best 0.708), test acc: 0.727 (best 0.727)\n",
      "In epoch 35, loss: 1.056, val acc: 0.720 (best 0.720), test acc: 0.732 (best 0.730)\n",
      "In epoch 40, loss: 0.885, val acc: 0.740 (best 0.740), test acc: 0.746 (best 0.746)\n",
      "In epoch 45, loss: 0.726, val acc: 0.750 (best 0.750), test acc: 0.760 (best 0.760)\n",
      "In epoch 50, loss: 0.586, val acc: 0.752 (best 0.756), test acc: 0.759 (best 0.759)\n",
      "In epoch 55, loss: 0.469, val acc: 0.758 (best 0.758), test acc: 0.770 (best 0.767)\n",
      "In epoch 60, loss: 0.375, val acc: 0.762 (best 0.762), test acc: 0.770 (best 0.771)\n",
      "In epoch 65, loss: 0.300, val acc: 0.764 (best 0.764), test acc: 0.766 (best 0.768)\n",
      "In epoch 70, loss: 0.242, val acc: 0.770 (best 0.772), test acc: 0.769 (best 0.769)\n",
      "In epoch 75, loss: 0.197, val acc: 0.768 (best 0.772), test acc: 0.774 (best 0.769)\n",
      "In epoch 80, loss: 0.161, val acc: 0.766 (best 0.772), test acc: 0.776 (best 0.769)\n",
      "In epoch 85, loss: 0.134, val acc: 0.766 (best 0.772), test acc: 0.776 (best 0.769)\n",
      "In epoch 90, loss: 0.113, val acc: 0.766 (best 0.772), test acc: 0.773 (best 0.769)\n",
      "In epoch 95, loss: 0.096, val acc: 0.772 (best 0.772), test acc: 0.770 (best 0.769)\n"
     ]
    }
   ],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    for e in range(100):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "train(g, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4d762-4193-4bbb-8b9f-dc508c6792aa",
   "metadata": {},
   "source": [
    "In both example above we use 250 and 100 epochs to train the model, this suggests that \n",
    "300 is a good number to use as well [github dmlc](https://github.com/dmlc/dgl/tree/master/examples/pytorch/gat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f5c7aa-7525-4e20-95e4-40ae745c3718",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d4305-2389-421e-b9ae-51883e094ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn38",
   "language": "python",
   "name": "gnn38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
