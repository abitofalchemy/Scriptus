{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#7A74D9;\">Classification on imbalanced data</h1>\n",
    "\n",
    "Credict Card Fraud Detection\n",
    "\n",
    "The purpose of this notebook is to validate the code before adapting it to a new domain. \n",
    "\n",
    "**Table of contents**\n",
    "\n",
    "1. [Setup Imports](#setup)\n",
    "2. [Data processing](#data)\n",
    "    - Read/Load Data \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c anaconda seaborn -y\n",
    "# ! conda install -c anaconda scikit-learn  -y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load/Read Data \n",
    "\n",
    "file = tf.keras.utils\n",
    "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   9.604066e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    1.380247e+00  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.137433e+02 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -6.915971e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%   -5.433583e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    6.119264e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    3.480167e+01  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V26', 'V27', 'V28', 'Amount', 'Class']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time\n",
      "V1\n",
      "V2\n",
      "V3\n",
      "V4\n",
      "V5\n",
      "V6\n",
      "V7\n",
      "V8\n",
      "V9\n",
      "V10\n",
      "V11\n",
      "V12\n",
      "V13\n",
      "V14\n",
      "V15\n",
      "V16\n",
      "V17\n",
      "V18\n",
      "V19\n",
      "V20\n",
      "V21\n",
      "V22\n",
      "V23\n",
      "V24\n",
      "V25\n",
      "V26\n",
      "V27\n",
      "V28\n",
      "Amount\n",
      "Class\n"
     ]
    }
   ],
   "source": [
    "### No of Features\n",
    "for k in raw_df.columns: print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 284807\n",
      "    Positive: 492 (0.17% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Examine the class label imbalance\n",
    "\n",
    "# Let's look at the dataset imbalance:\n",
    "\n",
    "\n",
    "neg, pos = np.bincount(raw_df['Class'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean, split and normalize the data\n",
    "\n",
    "cleaned_df = raw_df.copy()\n",
    "\n",
    "# You don't want the `Time` column.\n",
    "cleaned_df.pop('Time')\n",
    "\n",
    "# The `Amount` column covers a huge range. Convert to log-space.\n",
    "eps = 0.001 # 0 => 0.1¢\n",
    "cleaned_df['Log Ammount'] = np.log(cleaned_df.pop('Amount')+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting the dataset\n",
    "\n",
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Class'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Class'))\n",
    "test_labels = np.array(test_df.pop('Class'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the input features\n",
    "\n",
    "Normalize the input features using the sklearn StandardScaler. This will set the mean to 0 and standard deviation to 1.\n",
    "\n",
    "> Note: The StandardScaler is only fit using the train_features to be sure the model is not peeking at the validation or test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (182276,)\n",
      "Validation labels shape: (45569,)\n",
      "Test labels shape: (56962,)\n",
      "Training features shape: (182276, 29)\n",
      "Validation features shape: (45569, 29)\n",
      "Test features shape: (56962, 29)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Log Ammount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.381213</td>\n",
       "      <td>2.533676</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.830602</td>\n",
       "      <td>-1.578708</td>\n",
       "      <td>-3.154342</td>\n",
       "      <td>0.460081</td>\n",
       "      <td>-1.392126</td>\n",
       "      <td>-2.143575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237407</td>\n",
       "      <td>0.756030</td>\n",
       "      <td>0.905754</td>\n",
       "      <td>0.770581</td>\n",
       "      <td>-1.035284</td>\n",
       "      <td>-0.568917</td>\n",
       "      <td>0.781444</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>1.270397</td>\n",
       "      <td>-1.455103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.480498</td>\n",
       "      <td>0.765324</td>\n",
       "      <td>-3.411207</td>\n",
       "      <td>2.259919</td>\n",
       "      <td>-2.222319</td>\n",
       "      <td>-1.579664</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>2.051740</td>\n",
       "      <td>-2.927040</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878504</td>\n",
       "      <td>1.733568</td>\n",
       "      <td>0.081069</td>\n",
       "      <td>1.005677</td>\n",
       "      <td>-0.280631</td>\n",
       "      <td>0.851215</td>\n",
       "      <td>0.577246</td>\n",
       "      <td>3.628193</td>\n",
       "      <td>-0.393347</td>\n",
       "      <td>-0.215259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>4.388952</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-3.361866</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-3.548950</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.122254</td>\n",
       "      <td>2.407607</td>\n",
       "      <td>-2.174497</td>\n",
       "      <td>-1.523660</td>\n",
       "      <td>0.220848</td>\n",
       "      <td>2.891829</td>\n",
       "      <td>-0.460155</td>\n",
       "      <td>3.845719</td>\n",
       "      <td>1.397665</td>\n",
       "      <td>0.819597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.190284</td>\n",
       "      <td>1.344987</td>\n",
       "      <td>-2.230753</td>\n",
       "      <td>1.541832</td>\n",
       "      <td>-2.603777</td>\n",
       "      <td>0.239713</td>\n",
       "      <td>-1.424916</td>\n",
       "      <td>1.227409</td>\n",
       "      <td>-1.803339</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360719</td>\n",
       "      <td>1.072327</td>\n",
       "      <td>0.411477</td>\n",
       "      <td>0.492285</td>\n",
       "      <td>-0.992280</td>\n",
       "      <td>-0.234168</td>\n",
       "      <td>-1.017804</td>\n",
       "      <td>1.765555</td>\n",
       "      <td>0.637919</td>\n",
       "      <td>1.556307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.840595</td>\n",
       "      <td>0.765054</td>\n",
       "      <td>-0.693746</td>\n",
       "      <td>1.583888</td>\n",
       "      <td>-1.844445</td>\n",
       "      <td>-0.670174</td>\n",
       "      <td>-1.934658</td>\n",
       "      <td>0.723967</td>\n",
       "      <td>-1.167020</td>\n",
       "      <td>-2.493593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115019</td>\n",
       "      <td>0.926912</td>\n",
       "      <td>1.010258</td>\n",
       "      <td>0.531512</td>\n",
       "      <td>0.647754</td>\n",
       "      <td>-0.526524</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>0.982902</td>\n",
       "      <td>0.345944</td>\n",
       "      <td>0.877618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -2.381213  2.533676 -5.000000  5.000000 -0.830602 -1.578708 -3.154342   \n",
       "1 -2.480498  0.765324 -3.411207  2.259919 -2.222319 -1.579664 -5.000000   \n",
       "2 -5.000000  5.000000 -5.000000  4.388952 -5.000000 -3.361866 -5.000000   \n",
       "3 -1.190284  1.344987 -2.230753  1.541832 -2.603777  0.239713 -1.424916   \n",
       "4 -0.840595  0.765054 -0.693746  1.583888 -1.844445 -0.670174 -1.934658   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.460081 -1.392126 -2.143575  ... -0.237407  0.756030  0.905754  0.770581   \n",
       "1  2.051740 -2.927040 -5.000000  ...  0.878504  1.733568  0.081069  1.005677   \n",
       "2  5.000000 -3.548950 -5.000000  ...  2.122254  2.407607 -2.174497 -1.523660   \n",
       "3  1.227409 -1.803339 -5.000000  ...  0.360719  1.072327  0.411477  0.492285   \n",
       "4  0.723967 -1.167020 -2.493593  ...  0.115019  0.926912  1.010258  0.531512   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Log Ammount  \n",
       "0 -1.035284 -0.568917  0.781444 -5.000000  1.270397    -1.455103  \n",
       "1 -0.280631  0.851215  0.577246  3.628193 -0.393347    -0.215259  \n",
       "2  0.220848  2.891829 -0.460155  3.845719  1.397665     0.819597  \n",
       "3 -0.992280 -0.234168 -1.017804  1.765555  0.637919     1.556307  \n",
       "4  0.647754 -0.526524  1.669922  0.982902  0.345944     0.877618  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_df = pd.DataFrame(train_features[ bool_train_labels], columns=train_df.columns)\n",
    "neg_df = pd.DataFrame(train_features[~bool_train_labels], columns=train_df.columns)\n",
    "\n",
    "display(pos_df.head())\n",
    "if 0:\n",
    "    sns.jointplot(pos_df['V5'], pos_df['V6'],\n",
    "                  kind='hex', xlim=(-5,5), ylim=(-5,5))\n",
    "    plt.suptitle(\"Positive distribution\")\n",
    "\n",
    "    sns.jointplot(neg_df['V5'], neg_df['V6'],\n",
    "                  kind='hex', xlim=(-5,5), ylim=(-5,5))\n",
    "    _ = plt.suptitle(\"Negative distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "  model = keras.Sequential([\n",
    "      keras.layers.Dense(\n",
    "          16, activation='relu',\n",
    "          input_shape=(train_features.shape[-1],)),\n",
    "      keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(1, activation='sigmoid',\n",
    "                         bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test run the model:\n",
    "\n",
    "\n",
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Initial Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the bias fix helps\n",
    "\n",
    "# Before moving on, confirm quick that the careful bias initialization actually helped.\n",
    "\n",
    "# Train the model for 20 epochs, with and without this careful initialization, and compare the losses:\n",
    "\n",
    "\n",
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "model.layers[-1].bias.assign([0.0])\n",
    "zero_bias_history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels), \n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "careful_bias_history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels), \n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
    "plot_loss(careful_bias_history, \"Careful Bias\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model\n",
    "\n",
    "\n",
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "baseline_history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check training history\n",
    "\n",
    "In this section, you will produce plots of your model's accuracy and loss on the training and validation set. These are useful to check for overfitting, which you can learn more about in the Overfit and underfit tutorial.\n",
    "\n",
    "Additionally, you can produce these plots for any of the metrics you created above. False negatives are included as an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(baseline_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate metrics\n",
    "\n",
    "You can use a confusion matrix to summarize the actual vs. predicted labels, where the X axis is the predicted label and the Y axis is the actual label:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = model.evaluate(test_features, test_labels,\n",
    "                                  batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the ROC\n",
    "\n",
    "#  Now plot the ROC. This plot is useful because it shows, at a glance, \n",
    "# the range of performance the model can reach just by tuning the \n",
    "# output threshold.\n",
    "\n",
    "\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([-0.5,20])\n",
    "  plt.ylim([80,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the AUPRC\n",
    "\n",
    "Now plot the AUPRC. Area under the interpolated precision-recall curve, obtained by plotting (recall, precision) points for different values of the classification threshold. Depending on how it's calculated, PR AUC may be equivalent to the average precision of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_prc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(val_features, val_labels),\n",
    "    # The class weights go here\n",
    "    class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check training history\n",
    "\n",
    "\n",
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate metrics\n",
    "\n",
    "\n",
    "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_results = weighted_model.evaluate(test_features, test_labels,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the ROC\n",
    "\n",
    "\n",
    "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
    "plot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the AUPRC\n",
    "\n",
    "\n",
    "plot_prc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_prc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_prc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
    "plot_prc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "\n",
    "Oversample the minority class\n",
    "\n",
    "A related approach would be to resample the dataset by oversampling the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features = train_features[bool_train_labels]\n",
    "neg_features = train_features[~bool_train_labels]\n",
    "\n",
    "pos_labels = train_labels[bool_train_labels]\n",
    "neg_labels = train_labels[~bool_train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfnv",
   "language": "python",
   "name": "tfnv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
